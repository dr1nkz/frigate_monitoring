{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from detector import YOLOv8\n",
    "from utils import compute_polygon_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewTransformer:\n",
    "    def __init__(self, source: np.ndarray, target: np.ndarray) -> None:\n",
    "        source = source.astype(np.float32)\n",
    "        target = target.astype(np.float32)\n",
    "        self.m = cv2.getPerspectiveTransform(source, target)\n",
    "\n",
    "    def transform_points(self, points: np.ndarray) -> np.ndarray:\n",
    "        if points.size == 0:\n",
    "            return points\n",
    "\n",
    "        reshaped_points = points.reshape(-1, 1, 2).astype(np.float32)\n",
    "        transformed_points = cv2.perspectiveTransform(\n",
    "                reshaped_points, self.m)\n",
    "        return transformed_points.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = np.array([\n",
    "    [1252, 787], \n",
    "    [2298, 803], \n",
    "    [5039, 2159], \n",
    "    [-550, 2159]\n",
    "])\n",
    "\n",
    "TARGET_WIDTH = 25\n",
    "TARGET_HEIGHT = 250\n",
    "\n",
    "TARGET = np.array([\n",
    "    [0, 0],\n",
    "    [24, 0],\n",
    "    [24, 249],\n",
    "    [0, 249],\n",
    "])\n",
    "view_transformer = ViewTransformer(source=SOURCE, target=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(r'http://localhost:5000/api/events/1711485879.618846-sdaj55').text\n",
    "response = json.loads(response)\n",
    "response['end_time'] is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gen() missing 2 required positional arguments: 'camera' and 'event_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# out.release()\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# gen(r'rtsp://admin:admin@192.168.0.39:1935')\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrtsp://localhost:8554/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: gen() missing 2 required positional arguments: 'camera' and 'event_id'"
     ]
    }
   ],
   "source": [
    "def gen(address):#, camera, event_id):\n",
    "    \"\"\"\n",
    "    Запуск модели\n",
    "    \"\"\"    \n",
    "    model_path = r'./hf.onnx'\n",
    "    yolov8_detector = YOLOv8(path=model_path,\n",
    "                             conf_thres=0.3,\n",
    "                             iou_thres=0.5)\n",
    "    \n",
    "    # address = f'rtsp://localhost:8554/{camera}'\n",
    "\n",
    "    cv2.namedWindow('stream', cv2.WINDOW_NORMAL)\n",
    "    cap = cv2.VideoCapture(address)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # filename = './video_' + \\\n",
    "    #     datetime.now().strftime(r'_%d.%m.%Y_%H:%M:%S') + '.mp4'\n",
    "    # out = cv2.VideoWriter(filename, fourcc, 30, (width, height))\n",
    "\n",
    "    coordinates = defaultdict(lambda: deque(maxlen=fps))\n",
    "\n",
    "    # response = requests.get(f'http://localhost:5000/api/events/{event_id}').text\n",
    "    # response_json = json.loads(response)\n",
    "    # end_time = response_json['end_time']\n",
    "\n",
    "    while cap.isOpened():# and end_time is None:\n",
    "        # Кадр с камеры\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Детектирование\n",
    "        detected_img = frame.copy()\n",
    "        bounding_boxes, scores, class_ids = yolov8_detector(detected_img)\n",
    "        print(bounding_boxes)\n",
    "        bounding_boxes = np.array(bounding_boxes)\n",
    "        detected_img = yolov8_detector.draw_detections(detected_img)\n",
    "        if detected_img is None:\n",
    "            continue\n",
    "\n",
    "        # чтобы не ломалось iou\n",
    "        if len(bounding_boxes) == 1 or bounding_boxes.shape[0] == 1:\n",
    "            # bounding_boxes = np.array([bounding_boxes])\n",
    "            bounding_boxes = np.array(bounding_boxes).reshape(1, -1)\n",
    "\n",
    "        # Bottom center anchors\n",
    "        points = np.array([[x_1 + x_2 / 2, y] for [x_1, _, x_2, y] in bounding_boxes])\n",
    "        points = view_transformer.transform_points(points=points).astype(int)\n",
    "\n",
    "        # for class_id, [_, y] in zip(class_ids, points):\n",
    "        for class_id, [_, y] in enumerate(points):\n",
    "            coordinates[class_id].append(y)\n",
    "        \n",
    "        # for class_id, bounding_box in zip(class_ids, bounding_boxes):\n",
    "        for class_id, bounding_box in enumerate(bounding_boxes):\n",
    "            # wait to have enough data\n",
    "            if len(coordinates[class_id]) > fps / 2:\n",
    "                # calculate the speed\n",
    "                coordinate_start = coordinates[class_id][-1]\n",
    "                coordinate_end = coordinates[class_id][0]\n",
    "                distance = abs(coordinate_start - coordinate_end)\n",
    "                time = len(coordinates[class_id]) / fps\n",
    "                speed = distance / time * 3.6\n",
    "\n",
    "                caption = f'{int(speed)} km/h' # надпись\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX # font\n",
    "                fontScale = 1 # fontScale\n",
    "                thickness = 2 # Line thickness of 2 px\n",
    "                x_1 = bounding_box[0]\n",
    "                y_1 = bounding_box[1]\n",
    "                x_2 = bounding_box[2]\n",
    "                y_2 = bounding_box[3]\n",
    "                # Using cv2.putText() method\n",
    "                cv2.putText(detected_img, caption, (int(x_1 + 2), int(y_1 + (y_2 - y_1) / 2)),\n",
    "                            font, fontScale, (255, 0, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('stream', detected_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        # out.write(detected_img) # frame\n",
    "        # response = requests.get(f'http://localhost:5000/api/events/{event_id}').text\n",
    "        # response_json = json.loads(response)\n",
    "        # end_time = response_json['end_time']\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    # out.release()\n",
    "\n",
    "# gen(r'rtsp://admin:admin@192.168.0.39:1935')\n",
    "gen(r'rtsp://localhost:8554/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@64.239] global cap.cpp:164 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.0) /io/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): http://localhost:8554/test in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def stream(address):\n",
    "\n",
    "    cv2.namedWindow('stream', cv2.WINDOW_NORMAL)\n",
    "    cap = cv2.VideoCapture(address)\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    # width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    # height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Кадр с камеры\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow('stream', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "stream(r'http://localhost:8554/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
