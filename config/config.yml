mqtt:
  enabled: false

detect:
  # Optional: width of the frame for the input with the detect role (default: use native stream resolution)
  width: 720
  # Optional: height of the frame for the input with the detect role (default: use native stream resolution)
  height: 480
  # Optional: desired fps for your camera for the input with the detect role (default: shown below)
  # NOTE: Recommended value of 5. Ideally, try and reduce your FPS on the camera.
  fps: 5
  # Optional: enables detection for the camera (default: True)
  enabled: true
  # Optional: Number of consecutive detection hits required for an object to be initialized in the tracker. (default: 1/2 the frame rate)
  min_initialized: 2
  # Optional: Number of frames without a detection before Frigate considers an object to be gone. (default: 5x the frame rate)
  max_disappeared: 25
  # Optional: Configuration for stationary object tracking
  stationary:
    # Optional: Frequency for confirming stationary objects (default: same as threshold)
    # When set to 1, object detection will run to confirm the object still exists on every frame.
    # If set to 10, object detection will run to confirm the object still exists on every 10th frame.
    interval: 50
    # Optional: Number of frames without a position change for an object to be considered stationary (default: 10x the frame rate or 10s)
    threshold: 50
    # Optional: Define a maximum number of frames for tracking a stationary object (default: not set, track forever)
    # This can help with false positives for objects that should only be stationary for a limited amount of time.
    # It can also be used to disable stationary object tracking. For example, you may want to set a value for person, but leave
    # car at the default.
    # WARNING: Setting these values overrides default behavior and disables stationary object tracking.
    #          There are very few situations where you would want it disabled. It is NOT recommended to
    #          copy these values from the example config into your config unless you know they are needed.
    max_frames:
      # Optional: Default for all object types (default: not set, track forever)
      default: 3000
  # Optional: Milliseconds to offset detect annotations by (default: shown below).
  # There can often be latency between a recording and the detect process,
  # especially when using separate streams for detect and record.
  # Use this setting to make the timeline bounding boxes more closely align
  # with the recording. The value can be positive or negative.
  # TIP: Imagine there is an event clip with a person walking from left to right.
  #      If the event timeline bounding box is consistently to the left of the person
  #      then the value should be decreased. Similarly, if a person is walking from
  #      left to right and the bounding box is consistently ahead of the person
  #      then the value should be increased.
  # TIP: This offset is dynamic so you can change the value and it will update existing
  #      events, this makes it easy to tune.
  # WARNING: Fast moving objects will likely not have the bounding box align.
  annotation_offset: 0

objects:
  # Optional: list of objects to track from labelmap.txt (default: shown below)
  track:
  - person
  - bicycle
  - car
  - motorcycle
  - airplane
  - bus
  - train
  - car
  - boat
  - traffic
  - light
  - fire
  - hydrant
  - street
  - sign
  - stop
  - sign
  - parking
  - meter
  - bench
  - bird
  - cat
  - dog
  - horse
  - sheep
  - cow
  - elephant
  - bear
  - zebra
  - giraffe
  - hat
  - backpack
  - umbrella
  - shoe
  - eye
  - glasses
  - handbag
  - tie
  - suitcase
  - frisbee
  - skis
  - snowboard
  - sports
  - ball
  - kite
  - baseball
  - bat
  - baseball
  - glove
  - skateboard
  - surfboard
  - tennis
  - racket
  - bottle
  - plate
  - wine
  - glass
  - cup
  - fork
  - knife
  - spoon
  - bowl
  - banana
  - apple
  - sandwich
  - orange
  - broccoli
  - carrot
  - hot
  - dog
  - pizza
  - donut
  - cake
  - chair
  - couch
  - potted
  - plant
  - bed
  - mirror
  - dining
  - table
  - window
  - desk
  - toilet
  - door
  - tv
  - laptop
  - mouse
  - remote
  - keyboard
  - cell
  - phone
  - microwave
  - oven
  - toaster
  - sink
  - refrigerator
  - blender
  - book
  - clock
  - vase
  - scissors
  - teddy
  - bear
  - hair
  - drier
  - toothbrush
  - hair
  - brush
  # Optional: mask to prevent all object types from being detected in certain areas (default: no mask)
  # Checks based on the bottom center of the bounding box of the object.
  # NOTE: This mask is COMBINED with the object type specific mask below
  # mask: 0,0,1000,0,1000,200,0,200  

# Optional: Detectors configuration. Defaults to a single CPU detector
detectors:
  # Required: name of the detector
  detector_name:
    # Required: type of the detector
    # Frigate provided types include 'cpu', 'edgetpu', 'openvino' and 'tensorrt' (default: shown below)
    # Additional detector types can also be plugged in.
    # Detectors may require additional configuration.
    # Refer to the Detectors configuration page for more information.
    type: cpu

# Optional: model modifications
model:
  # Optional: path to the model (default: automatic based on detector)
  path: /cpu_model.tflite
  # path: /config/yolov8n.pt
  # Optional: path to the labelmap (default: shown below)
  labelmap_path: /labelmap.txt
  # Required: Object detection model input width (default: shown below)
  width: 320
  # Required: Object detection model input height (default: shown below)
  height: 320
  # Optional: Object detection model input colorspace
  # Valid values are rgb, bgr, or yuv. (default: shown below)
  input_pixel_format: rgb
  # Optional: Object detection model input tensor format
  # Valid values are nhwc or nchw (default: shown below)
  input_tensor: nhwc
  # Optional: Object detection model type, currently only used with the OpenVINO detector
  # Valid values are ssd, yolox, yolov5, or yolov8 (default: shown below)
  model_type: ssd
  # model_type: yolov8
  # Optional: Label name modifications. These are merged into the standard labelmap.
  # labelmap:
  #   2: vehicle

record:
  # Optional: Enable recording (default: shown below)
  # WARNING: If recording is disabled in the config, turning it on via
  #          the UI or MQTT later will have no effect.
  enabled: true
  # Optional: Number of minutes to wait between cleanup runs (default: shown below)
  # This can be used to reduce the frequency of deleting recording segments from disk if you want to minimize i/o
  expire_interval: 60
  # Optional: Sync recordings with disk on startup and once a day (default: shown below).
  sync_recordings: false
  # Optional: Retention settings for recording
  retain:
    # Optional: Number of days to retain recordings regardless of events (default: shown below)
    # NOTE: This should be set to 0 and retention should be defined in events section below
    #       if you only want to retain recordings of events.
    days: 3
    # Optional: Mode for retention. Available options are: all, motion, and active_objects
    #   all - save all recording segments regardless of activity
    #   motion - save all recordings segments with any detected motion
    #   active_objects - save all recording segments with active/moving objects
    # NOTE: this mode only applies when the days setting above is greater than 0
    mode: all
  # Optional: Recording Export Settings
  export:
    # Optional: Timelapse Output Args (default: shown below).
    # NOTE: The default args are set to fit 24 hours of recording into 1 hour playback.
    # See https://stackoverflow.com/a/58268695 for more info on how these args work.
    # As an example: if you wanted to go from 24 hours to 30 minutes that would be going
    # from 86400 seconds to 1800 seconds which would be 1800 / 86400 = 0.02.
    # The -r (framerate) dictates how smooth the output video is.
    # So the args would be -vf setpts=0.02*PTS -r 30 in that case.
    timelapse_args: -vf setpts=0.04*PTS -r 30
  # Optional: Event recording settings
  events:
    # Optional: Number of seconds before the event to include (default: shown below)
    pre_capture: 5
    # Optional: Number of seconds after the event to include (default: shown below)
    post_capture: 5
    # Optional: Objects to save recordings for. (default: all tracked objects)
    # objects:
    #   - person
    # Optional: Restrict recordings to objects that entered any of the listed zones (default: no required zones)
    # required_zones: []
    # Optional: Retention settings for recordings of events
    retain:
      # Required: Default retention days (default: shown below)
      default: 10
      # Optional: Mode for retention. (default: shown below)
      #   all - save all recording segments for events regardless of activity
      #   motion - save all recordings segments for events with any detected motion
      #   active_objects - save all recording segments for event with active/moving objects
      #
      # NOTE: If the retain mode for the camera is more restrictive than the mode configured
      #       here, the segments will already be gone by the time this mode is applied.
      #       For example, if the camera retain mode is "motion", the segments without motion are
      #       never stored, so setting the mode to "all" here won't bring them back.
      mode: motion
      # Optional: Per object retention days
      # objects:
      #   person: 15

cameras:
  test:
    enabled: true

    ffmpeg:
      hwaccel_args: preset-nvidia-h264
      inputs:
      - path: http://192.168.0.39:8080/video
        input_args: -re -stream_loop -1 -fflags +genpts
        roles:
        - detect
        # - record
        # - rtmp
      - path: http://192.168.0.39:8080/video
        input_args: -re -stream_loop -1 -fflags +genpts
        roles:
        - record

    zones:
      # zone_0:
      #   coordinates: 689,203,684,79,544,62
      zone_1:
        coordinates: 39,340,380,342,362,0,68,0
        # Optional: Number of consecutive frames required for object to be considered present in the zone (default: shown below).
        inertia: 50
